# FIAP TECH CHALLENGE ‚Äì FASE 4

## Grupo 118

### Participantes

- **Armando Jos√© Vieira Dias de Oliveira**  
  GitHub: `@armandojoseoliveira` ‚Äî User: *Nando*  
  RM361112

- **Marlon dos Santos Limeira**  
  GitHub: `@marlonsantos4509` ‚Äî User: *Marlon Santos*  
  RM361866

- **Matheus Nascimento Costa**  
  GitHub: `@matheus_coast` ‚Äî User: *Matheus_coast*  
  RM363404

- **Ricardo Noronha de Menezes**  
  GitHub: `@ricardo_nm` ‚Äî User: *ricardo_nm*  
  RM363183

---

### Observa√ß√£o Importante

> Embora os reposit√≥rios fa√ßam refer√™ncia √† **Fase 3**, o c√≥digo e a solu√ß√£o apresentados correspondem √† **Fase 4**, pois o grupo optou por evoluir o mesmo projeto de forma cont√≠nua.

---

## Reposit√≥rios de C√≥digo

- **Payments**  
  https://github.com/ricardonoronha/fcg-fase3-payments

- **Users**  
  https://github.com/ricardonoronha/fcg-fase3-users

- **Games**  
  https://github.com/ricardonoronha/fcg-fase3-games

---

## V√≠deo de Demonstra√ß√£o

- üé• https://youtu.be/bTZaDeKj-LQ

---

## Documenta√ß√£o DDD (Event Storming)

- üìå https://miro.com/app/board/uXjVIE9R-Pg=/?share_link_id=308339772603

---

# Documenta√ß√£o T√©cnica ‚Äì Tech Challenge

## Vis√£o Geral da Solu√ß√£o

Este projeto foi desenvolvido como parte do **Tech Challenge**, com o objetivo de implementar uma arquitetura de **microsservi√ßos moderna**, executando em **Kubernetes**, com foco em:

- Observabilidade
- Comunica√ß√£o ass√≠ncrona
- Boas pr√°ticas de Cloud Native

A solu√ß√£o simula um cen√°rio real de sistemas distribu√≠dos, contemplando microsservi√ßos independentes, integra√ß√£o via mensageria, infraestrutura containerizada e monitoramento cont√≠nuo.

O foco principal foi entregar uma solu√ß√£o **funcional**, **coerente** e **alinhada com pr√°ticas reais de produ√ß√£o**.

---

## Arquitetura Geral

A arquitetura da solu√ß√£o √© composta por **microsservi√ßos backend independentes**, respons√°veis por dom√≠nios distintos da aplica√ß√£o, integrados por mensageria.

### Componentes Principais

- Microsservi√ßo **Games**
- Microsservi√ßo **Payments**
- Microsservi√ßo **Users**
- **RabbitMQ** para comunica√ß√£o ass√≠ncrona
- **Kubernetes (Azure Kubernetes Service ‚Äì AKS)**
- **Prometheus** para coleta de m√©tricas
- **Grafana** para visualiza√ß√£o e an√°lise
- **Azure Container Registry (ACR)** para armazenamento de imagens Docker

---

### Fluxo de Comunica√ß√£o (Simplificado)

- O microsservi√ßo **Payments** atua como **produtor de mensagens**, publicando eventos no RabbitMQ.
- O microsservi√ßo **Games** consome essas mensagens de forma **ass√≠ncrona**, processando os eventos recebidos.
- Os servi√ßos e a infraestrutura exp√µem m√©tricas que s√£o coletadas pelo **Prometheus** e visualizadas no **Grafana**.

---

## Tecnologias Utilizadas

### Backend

- .NET 8
- ASP.NET Core Web API
- Configura√ß√£o baseada em vari√°veis de ambiente

### Containers

- Docker
- Dockerfiles com **multi-stage build**
- Imagens otimizadas para execu√ß√£o em Kubernetes

### Orquestra√ß√£o

- Kubernetes (AKS)
- Namespaces para organiza√ß√£o de recursos
- Services para comunica√ß√£o interna
- ConfigMaps e Secrets para configura√ß√£o
- Liveness e Readiness Probes

### Mensageria

- RabbitMQ
- Comunica√ß√£o ass√≠ncrona entre microsservi√ßos
- Configura√ß√£o via vari√°veis de ambiente e Secrets

### Observabilidade

- Prometheus para coleta de m√©tricas
- Grafana para dashboards e visualiza√ß√£o

### Cloud

- Microsoft Azure
- Azure Kubernetes Service (AKS)
- Azure Container Registry (ACR)

---

## Observabilidade e Monitoramento

Foi implementada uma camada de observabilidade com foco inicial em **CPU e mem√≥ria**, utilizando Prometheus e Grafana.

### M√©tricas Monitoradas

- Consumo de CPU do cluster
- Consumo de mem√≥ria por n√≥
- Estado geral dos n√≥s do Kubernetes

As m√©tricas s√£o coletadas a partir dos exporters do cluster Kubernetes e apresentadas em dashboards no Grafana, permitindo an√°lise em tempo real e suporte ao diagn√≥stico de desempenho.

---

## Deploy e Execu√ß√£o da Solu√ß√£o

O processo de deploy segue as etapas abaixo:

1. Build das imagens Docker dos microsservi√ßos
2. Publica√ß√£o das imagens no Azure Container Registry
3. Cria√ß√£o dos manifests Kubernetes (YAML)
4. Deploy dos servi√ßos no cluster AKS
5. Exposi√ß√£o dos servi√ßos internamente no cluster
6. Monitoramento cont√≠nuo via Prometheus e Grafana

Os manifests Kubernetes foram organizados separando claramente:

- Namespaces
- Services
- ConfigMaps
- Secrets

Essa organiza√ß√£o facilita manuten√ß√£o e entendimento da infraestrutura.

---

## Boas Pr√°ticas Aplicadas

Durante o desenvolvimento da solu√ß√£o, foram aplicadas as seguintes boas pr√°ticas:

- Separa√ß√£o clara de responsabilidades entre microsservi√ßos
- Comunica√ß√£o ass√≠ncrona para redu√ß√£o de acoplamento
- Containers imut√°veis
- Configura√ß√£o externa via vari√°veis de ambiente
- Observabilidade desde o in√≠cio do projeto
- Foco em simplicidade e funcionamento real

As decis√µes t√©cnicas priorizaram clareza, coer√™ncia arquitetural e ader√™ncia a padr√µes modernos de engenharia de software.

---

## Limita√ß√µes Conhecidas e Pr√≥ximos Passos

Devido ao escopo e tempo dispon√≠vel, alguns pontos ficaram como evolu√ß√µes futuras:

- Implementa√ß√£o de CI/CD automatizado
- Estrat√©gias avan√ßadas de retry e dead-letter no RabbitMQ
- Tracing distribu√≠do com OpenTelemetry
- Autoscaling horizontal com HPA
- Monitoramento de m√©tricas de aplica√ß√£o

Essas melhorias podem ser implementadas sem necessidade de reestrutura√ß√£o da arquitetura atual.

---

## Conclus√£o

A solu√ß√£o entregue atende aos objetivos propostos pelo **Tech Challenge**, demonstrando dom√≠nio pr√°tico em:

- Microsservi√ßos
- Containers
- Kubernetes
- Mensageria
- Observabilidade

O projeto priorizou uma arquitetura funcional, realista e alinhada com cen√°rios profissionais, servindo como base s√≥lida para evolu√ß√µes futuras.
